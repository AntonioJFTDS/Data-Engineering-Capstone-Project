{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "* 1: Project's scope and Data Gathering \n",
    "* 2: Data Exploration and Assessement of the Data\n",
    "* 3: The Data Model\n",
    "* 4: The ETL to Model the Data\n",
    "* 5: Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1: Project's scope and Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### The Scope \n",
    "##### Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "The plan is to create a fact-dimension database using Apache Spark, with the I-94 immigration dataset as the fact table. The dimension tables will include weather and economic data from the country of residency before arrival in the U.S. and the state of residency in the U.S.\n
This database will enable analysis of the relationship between economic conditions in the country of origin and the chosen U.S. state, as well as the correlation between temperatures in both locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Gathering and Description \n",
    "\n",
    "- ##### i94_apr16_sub.sas7bdat (Udacity Dataset): \n",
    "    Shows for April 1996, all the DHS Arrival/Departure records issued to aliens who are admitted to the U.S., who are adjusting status while in the U.S. or extending their stay, among other things. \n",
    "    ps: An alien is any individual who is not a U.S. citizen or U.S. national.\n",
    "\n",
    "- ##### political_stability_country.csv (https://databank.worldbank.org/source/worldwide-governance-indicators#): \n",
    "    Shows political stability score per country per year since 1996.\n",
    "\n",
    "    The Political Stability and Absence of Violence/Terrorism score measures perceptions of the likelihood of political instability and/or politically-motivated violence, including terrorism. Ranging from  -2.682813 to 1.526126.\n",
    "\n",
    "- ##### unemployment_country.csv (https://databank.worldbank.org/source/world-development-indicators#): \n",
    "    Shows unemployment with advanced education, Unemployment with basic education, Unemployment with intermediate education, Unemployment total per year since 1996. \n",
    "\n",
    "- ##### population_country.csv (https://www.kaggle.com/datasets/imdevskp/world-population-19602018?select=population_total_long.csv): \n",
    "    Shows population per country per year since 1996.\n",
    "\n",
    "- ##### unemployment_us_state.csv (https://www.kaggle.com/datasets/jayrav13/unemployment-by-county-us): \n",
    "    Shows unemployment in U.S for each state since 1996.\n",
    "    \n",
    "- ##### temperature.csv (https://www.kaggle.com/datasets/sudalairajkumar/daily-temperature-of-major-cities): \n",
    "    Shows average temperature per country, per state, per city, per day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2: Data Exploration and Assessement of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1 Data Exploration\n",
    "Identifing data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1.1 Dataset: i94_apr16_sub.sas7bdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cicid : \n",
      " nb_nunique : 3096313  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [  6.   7.  15.  16.  17.  18.  19.  20.  21.  22.] \n",
      "\n",
      "\n",
      "i94yr : \n",
      " nb_nunique : 1  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [ 2016.] \n",
      "\n",
      "\n",
      "i94mon : \n",
      " nb_nunique : 1  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [ 4.] \n",
      "\n",
      "\n",
      "i94cit : \n",
      " nb_nunique : 243  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [ 692.  254.  101.  102.  103.  104.  105.  107.  108.  109.] \n",
      "\n",
      "\n",
      "i94res : \n",
      " nb_nunique : 229  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [ 692.  276.  101.  110.  117.  112.  251.  102.  103.  104.] \n",
      "\n",
      "\n",
      "i94port : \n",
      " nb_nunique : 299  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : ['XXX' 'ATL' 'WAS' 'NYC' 'TOR' 'BOS' 'HOU' 'MIA' 'CHI' 'LOS'] \n",
      "\n",
      "\n",
      "arrdate : \n",
      " nb_nunique : 30  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [ 20573.  20551.  20545.  20546.  20547.  20548.  20549.  20550.  20552.\n",
      "  20553.] \n",
      "\n",
      "\n",
      "i94mode : \n",
      " nb_nunique : 4  \n",
      " perct_null : 0.01% \n",
      " examples of unique values : [ nan   1.   2.   9.   3.] \n",
      "\n",
      "\n",
      "i94addr : \n",
      " nb_nunique : 458  \n",
      " perct_null : 4.92% \n",
      " examples of unique values : [nan 'AL' 'MI' 'MA' 'NJ' 'NY' 'MO' 'TX' 'CT' 'FL'] \n",
      "\n",
      "\n",
      "depdate : \n",
      " nb_nunique : 235  \n",
      " perct_null : 4.60% \n",
      " examples of unique values : [    nan  20691.  20567.  20555.  20558.  20553.  20562.  20671.  20554.\n",
      "  20549.] \n",
      "\n",
      "\n",
      "i94bir : \n",
      " nb_nunique : 112  \n",
      " perct_null : 0.03% \n",
      " examples of unique values : [ 37.  25.  55.  28.   4.  57.  63.  46.  48.  52.] \n",
      "\n",
      "\n",
      "i94visa : \n",
      " nb_nunique : 3  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [ 2.  3.  1.] \n",
      "\n",
      "\n",
      "count : \n",
      " nb_nunique : 1  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [ 1.] \n",
      "\n",
      "\n",
      "dtadfile : \n",
      " nb_nunique : 117  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [nan '20130811' '20160401' '20160402' '20160403' '20160404' '20160405'\n",
      " '20160406' '20160407' '20160408'] \n",
      "\n",
      "\n",
      "visapost : \n",
      " nb_nunique : 530  \n",
      " perct_null : 60.76% \n",
      " examples of unique values : [nan 'SEO' 'TIA' 'HLS' 'FLR' 'NPL' 'RME' 'BRL' 'FRN' 'TLV'] \n",
      "\n",
      "\n",
      "occup : \n",
      " nb_nunique : 111  \n",
      " perct_null : 99.74% \n",
      " examples of unique values : [nan 'ELT' 'PHS' 'EXA' 'STU' 'MKT' 'TIP' 'ULS' 'OTH' 'RPT'] \n",
      "\n",
      "\n",
      "entdepa : \n",
      " nb_nunique : 13  \n",
      " perct_null : 0.01% \n",
      " examples of unique values : ['T' 'G' 'O' 'H' 'U' 'B' 'K' 'M' 'F' nan] \n",
      "\n",
      "\n",
      "entdepd : \n",
      " nb_nunique : 12  \n",
      " perct_null : 4.47% \n",
      " examples of unique values : [nan 'O' 'K' 'I' 'Q' 'R' 'N' 'M' 'J' 'D'] \n",
      "\n",
      "\n",
      "entdepu : \n",
      " nb_nunique : 2  \n",
      " perct_null : 99.99% \n",
      " examples of unique values : ['U' 'Y' nan] \n",
      "\n",
      "\n",
      "matflag : \n",
      " nb_nunique : 1  \n",
      " perct_null : 4.47% \n",
      " examples of unique values : [nan 'M'] \n",
      "\n",
      "\n",
      "biryear : \n",
      " nb_nunique : 112  \n",
      " perct_null : 0.03% \n",
      " examples of unique values : [ 1979.  1991.  1961.  1988.  2012.  1959.  1953.  1970.  1968.  1964.] \n",
      "\n",
      "\n",
      "dtaddto : \n",
      " nb_nunique : 777  \n",
      " perct_null : 0.02% \n",
      " examples of unique values : ['10282016' 'D/S' '09302016' '04062016' '06292016' '03312018' '05202016'\n",
      " '10012016' '06262016' '06282016'] \n",
      "\n",
      "\n",
      "gender : \n",
      " nb_nunique : 4  \n",
      " perct_null : 13.38% \n",
      " examples of unique values : [nan 'M' 'F' 'X' 'U'] \n",
      "\n",
      "\n",
      "insnum : \n",
      " nb_nunique : 1913  \n",
      " perct_null : 96.33% \n",
      " examples of unique values : [nan '3181' '3148' '2295' '3511' '3451' '3993' '4171' '6758' '6962'] \n",
      "\n",
      "\n",
      "airline : \n",
      " nb_nunique : 534  \n",
      " perct_null : 2.70% \n",
      " examples of unique values : [nan 'OS' 'AA' 'AZ' 'TK' 'MQ' 'LH' 'AY' 'AB' 'AF'] \n",
      "\n",
      "\n",
      "admnum : \n",
      " nb_nunique : 3075579  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [  1.89762848e+09   3.73679633e+09   6.66643185e+08   9.24684613e+10\n",
      "   9.24684631e+10   9.24710380e+10   9.24713992e+10   9.24716138e+10\n",
      "   9.24707960e+10   9.24784897e+10] \n",
      "\n",
      "\n",
      "fltno : \n",
      " nb_nunique : 7152  \n",
      " perct_null : 0.63% \n",
      " examples of unique values : [nan '00296' '93' '00199' '00602' '00608' '00001' '03348' '00422' '00614'] \n",
      "\n",
      "\n",
      "visatype : \n",
      " nb_nunique : 17  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : ['B2' 'F1' 'B1' 'WT' 'WB' 'E2' 'I' 'F2' 'E1' 'M1'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_rows_df = len(df)\n",
    "for a_column in df.columns :\n",
    "    nb_nunique = df[a_column].nunique()\n",
    "    perct_null = df[a_column].isnull().sum()/nb_rows_df \n",
    "    unique_values= df[a_column].unique()\n",
    "    print(f\"{a_column} : \\n nb_nunique : {nb_nunique}  \\n perct_null : {perct_null:0.2%} \\n examples of unique values : {unique_values[0:10]} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1.2 Dataset: political_stability_country.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Series Code</th>\n",
       "      <th>1996</th>\n",
       "      <th>1998</th>\n",
       "      <th>2000</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>...</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Political Stability and Absence of Violence/Te...</td>\n",
       "      <td>PV.EST</td>\n",
       "      <td>-2.417309523</td>\n",
       "      <td>-2.427354574</td>\n",
       "      <td>-2.438968897</td>\n",
       "      <td>-2.035033703</td>\n",
       "      <td>-2.198372364</td>\n",
       "      <td>-2.295682192</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.418561459</td>\n",
       "      <td>-2.519349098</td>\n",
       "      <td>-2.411068439</td>\n",
       "      <td>-2.571221828</td>\n",
       "      <td>-2.671053886</td>\n",
       "      <td>-2.801083803</td>\n",
       "      <td>-2.763864279</td>\n",
       "      <td>-2.655531168</td>\n",
       "      <td>-2.705029726</td>\n",
       "      <td>-2.529855251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Political Stability and Absence of Violence/Te...</td>\n",
       "      <td>PV.EST</td>\n",
       "      <td>-0.336625129</td>\n",
       "      <td>-0.544004202</td>\n",
       "      <td>-0.539989591</td>\n",
       "      <td>-0.297719181</td>\n",
       "      <td>-0.30978024</td>\n",
       "      <td>-0.427259684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143631592</td>\n",
       "      <td>0.091929786</td>\n",
       "      <td>0.485986233</td>\n",
       "      <td>0.34612906</td>\n",
       "      <td>0.344644666</td>\n",
       "      <td>0.378474772</td>\n",
       "      <td>0.370515645</td>\n",
       "      <td>0.11116863</td>\n",
       "      <td>0.087552309</td>\n",
       "      <td>0.109445848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Political Stability and Absence of Violence/Te...</td>\n",
       "      <td>PV.EST</td>\n",
       "      <td>-1.783310533</td>\n",
       "      <td>-1.8789047</td>\n",
       "      <td>-1.432577372</td>\n",
       "      <td>-1.634565115</td>\n",
       "      <td>-1.754409075</td>\n",
       "      <td>-1.359188437</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.325043321</td>\n",
       "      <td>-1.202371478</td>\n",
       "      <td>-1.190535188</td>\n",
       "      <td>-1.090159774</td>\n",
       "      <td>-1.097525716</td>\n",
       "      <td>-0.915799141</td>\n",
       "      <td>-0.836119592</td>\n",
       "      <td>-1.044342637</td>\n",
       "      <td>-0.84025383</td>\n",
       "      <td>-0.876465023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>ASM</td>\n",
       "      <td>Political Stability and Absence of Violence/Te...</td>\n",
       "      <td>PV.EST</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>0.736926496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.95299083</td>\n",
       "      <td>0.928985775</td>\n",
       "      <td>1.08068347</td>\n",
       "      <td>1.181357265</td>\n",
       "      <td>1.193235755</td>\n",
       "      <td>1.21886313</td>\n",
       "      <td>1.216776371</td>\n",
       "      <td>1.172189116</td>\n",
       "      <td>1.174006343</td>\n",
       "      <td>1.049298167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>Political Stability and Absence of Violence/Te...</td>\n",
       "      <td>PV.EST</td>\n",
       "      <td>1.169522166</td>\n",
       "      <td>1.182875156</td>\n",
       "      <td>1.166981459</td>\n",
       "      <td>1.282766938</td>\n",
       "      <td>1.465131164</td>\n",
       "      <td>1.402106047</td>\n",
       "      <td>...</td>\n",
       "      <td>1.290351152</td>\n",
       "      <td>1.28392601</td>\n",
       "      <td>1.286593318</td>\n",
       "      <td>1.39128828</td>\n",
       "      <td>1.413419366</td>\n",
       "      <td>1.421868801</td>\n",
       "      <td>1.417627215</td>\n",
       "      <td>1.602202296</td>\n",
       "      <td>1.616035223</td>\n",
       "      <td>1.631808758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country Name Country Code  \\\n",
       "0     Afghanistan          AFG   \n",
       "1         Albania          ALB   \n",
       "2         Algeria          DZA   \n",
       "3  American Samoa          ASM   \n",
       "4         Andorra          AND   \n",
       "\n",
       "                                         Series Name Series Code  \\\n",
       "0  Political Stability and Absence of Violence/Te...      PV.EST   \n",
       "1  Political Stability and Absence of Violence/Te...      PV.EST   \n",
       "2  Political Stability and Absence of Violence/Te...      PV.EST   \n",
       "3  Political Stability and Absence of Violence/Te...      PV.EST   \n",
       "4  Political Stability and Absence of Violence/Te...      PV.EST   \n",
       "\n",
       "           1996          1998          2000          2002          2003  \\\n",
       "0  -2.417309523  -2.427354574  -2.438968897  -2.035033703  -2.198372364   \n",
       "1  -0.336625129  -0.544004202  -0.539989591  -0.297719181   -0.30978024   \n",
       "2  -1.783310533    -1.8789047  -1.432577372  -1.634565115  -1.754409075   \n",
       "3            ..            ..            ..            ..            ..   \n",
       "4   1.169522166   1.182875156   1.166981459   1.282766938   1.465131164   \n",
       "\n",
       "           2004      ...               2012          2013          2014  \\\n",
       "0  -2.295682192      ...       -2.418561459  -2.519349098  -2.411068439   \n",
       "1  -0.427259684      ...       -0.143631592   0.091929786   0.485986233   \n",
       "2  -1.359188437      ...       -1.325043321  -1.202371478  -1.190535188   \n",
       "3   0.736926496      ...         0.95299083   0.928985775    1.08068347   \n",
       "4   1.402106047      ...        1.290351152    1.28392601   1.286593318   \n",
       "\n",
       "           2015          2016          2017          2018          2019  \\\n",
       "0  -2.571221828  -2.671053886  -2.801083803  -2.763864279  -2.655531168   \n",
       "1    0.34612906   0.344644666   0.378474772   0.370515645    0.11116863   \n",
       "2  -1.090159774  -1.097525716  -0.915799141  -0.836119592  -1.044342637   \n",
       "3   1.181357265   1.193235755    1.21886313   1.216776371   1.172189116   \n",
       "4    1.39128828   1.413419366   1.421868801   1.417627215   1.602202296   \n",
       "\n",
       "           2020          2021  \n",
       "0  -2.705029726  -2.529855251  \n",
       "1   0.087552309   0.109445848  \n",
       "2   -0.84025383  -0.876465023  \n",
       "3   1.174006343   1.049298167  \n",
       "4   1.616035223   1.631808758  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'political_stability_country.csv'\n",
    "df = pd.read_csv(fname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country Name : \n",
      " nb_nunique : 216  \n",
      " perct_null : 1.37% \n",
      " examples of unique values : ['Afghanistan' 'Albania' 'Algeria' 'American Samoa' 'Andorra' 'Angola'\n",
      " 'Anguilla' 'Antigua and Barbuda' 'Argentina' 'Armenia'] \n",
      "\n",
      "\n",
      "Country Code : \n",
      " nb_nunique : 214  \n",
      " perct_null : 2.28% \n",
      " examples of unique values : ['AFG' 'ALB' 'DZA' 'ASM' 'AND' 'AGO' 'AIA' 'ATG' 'ARG' 'ARM'] \n",
      "\n",
      "\n",
      "variable : \n",
      " nb_nunique : 23  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : ['1996' '1998' '2000' '2002' '2003' '2004' '2005' '2006' '2007' '2008'] \n",
      "\n",
      "\n",
      "value : \n",
      " nb_nunique : 4570  \n",
      " perct_null : 2.28% \n",
      " examples of unique values : ['-2.417309523' '-0.336625129' '-1.783310533' '..' '1.169522166'\n",
      " '-2.061917305' '0.717076898' '0.111376882' '-0.364998609' '1.39611268'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Series Name','Series Code'],axis=1)\n",
    "df = pd.melt(df, id_vars=['Country Name','Country Code'], value_vars=list(df.columns)[2:])\n",
    "nb_rows_df = len(df)\n",
    "for a_column in df.columns :\n",
    "    nb_nunique = df[a_column].nunique()\n",
    "    perct_null = df[a_column].isnull().sum()/nb_rows_df \n",
    "    unique_values= df[a_column].unique()\n",
    "    print(f\"{a_column} : \\n nb_nunique : {nb_nunique}  \\n perct_null : {perct_null:0.2%} \\n examples of unique values : {unique_values[0:10]} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1.3 Dataset: unemployment_country.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Series Code</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>...</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Unemployment with advanced education (% of tot...</td>\n",
       "      <td>SL.UEM.ADVN.ZS</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>7.860000134</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>15.46000004</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>14.38000011</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Unemployment with basic education (% of total ...</td>\n",
       "      <td>SL.UEM.BASC.ZS</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>7.380000114</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>12.27999973</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>11.10000038</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Unemployment with intermediate education (% of...</td>\n",
       "      <td>SL.UEM.INTM.ZS</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>10.61999989</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>16.14999962</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>12.56999969</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Unemployment, total (% of total labor force) (...</td>\n",
       "      <td>SL.UEM.TOTL.NE.ZS</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>1.690000057</td>\n",
       "      <td>..</td>\n",
       "      <td>7.909999847</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>11.18000031</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>11.71000004</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Unemployment with advanced education (% of tot...</td>\n",
       "      <td>SL.UEM.ADVN.ZS</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>15.77000046</td>\n",
       "      <td>14.89999962</td>\n",
       "      <td>17.84000015</td>\n",
       "      <td>19.28000069</td>\n",
       "      <td>17.04999924</td>\n",
       "      <td>13.68999958</td>\n",
       "      <td>15.09000015</td>\n",
       "      <td>14.85999966</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name Country Code  \\\n",
       "0  Afghanistan          AFG   \n",
       "1  Afghanistan          AFG   \n",
       "2  Afghanistan          AFG   \n",
       "3  Afghanistan          AFG   \n",
       "4      Albania          ALB   \n",
       "\n",
       "                                         Series Name        Series Code 1996  \\\n",
       "0  Unemployment with advanced education (% of tot...     SL.UEM.ADVN.ZS   ..   \n",
       "1  Unemployment with basic education (% of total ...     SL.UEM.BASC.ZS   ..   \n",
       "2  Unemployment with intermediate education (% of...     SL.UEM.INTM.ZS   ..   \n",
       "3  Unemployment, total (% of total labor force) (...  SL.UEM.TOTL.NE.ZS   ..   \n",
       "4  Unemployment with advanced education (% of tot...     SL.UEM.ADVN.ZS   ..   \n",
       "\n",
       "  1997 1998 1999 2000 2001 ...          2012         2013         2014  \\\n",
       "0   ..   ..   ..   ..   .. ...            ..           ..  7.860000134   \n",
       "1   ..   ..   ..   ..   .. ...            ..           ..  7.380000114   \n",
       "2   ..   ..   ..   ..   .. ...            ..           ..  10.61999989   \n",
       "3   ..   ..   ..   ..   .. ...   1.690000057           ..  7.909999847   \n",
       "4   ..   ..   ..   ..   .. ...   15.77000046  14.89999962  17.84000015   \n",
       "\n",
       "          2015         2016         2017         2018         2019  \\\n",
       "0           ..           ..  15.46000004           ..           ..   \n",
       "1           ..           ..  12.27999973           ..           ..   \n",
       "2           ..           ..  16.14999962           ..           ..   \n",
       "3           ..           ..  11.18000031           ..           ..   \n",
       "4  19.28000069  17.04999924  13.68999958  15.09000015  14.85999966   \n",
       "\n",
       "          2020 2021  \n",
       "0  14.38000011   ..  \n",
       "1  11.10000038   ..  \n",
       "2  12.56999969   ..  \n",
       "3  11.71000004   ..  \n",
       "4           ..   ..  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'unemployment_country.csv'\n",
    "df = pd.read_csv(fname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country Name : \n",
      " nb_nunique : 235  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : ['Africa Eastern and Southern' 'Afghanistan' 'Africa Western and Central'\n",
      " 'Angola' 'Albania' 'Arab World' 'United Arab Emirates' 'Argentina'\n",
      " 'Armenia' 'Australia'] \n",
      "\n",
      "\n",
      "Country Code : \n",
      " nb_nunique : 235  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : ['AFE' 'AFG' 'AFW' 'AGO' 'ALB' 'ARB' 'ARE' 'ARG' 'ARM' 'AUS'] \n",
      "\n",
      "\n",
      "1996 : \n",
      " nb_nunique : 217  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [  7.84  10.96   4.57   4.1   13.93  12.38   1.9   17.11   9.3    8.51] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df[['Country Name','Country Code','1996']]\n",
    "nb_rows_df = len(df)\n",
    "for a_column in df.columns :\n",
    "    nb_nunique = df[a_column].nunique()\n",
    "    perct_null = df[a_column].isnull().sum()/nb_rows_df \n",
    "    unique_values= df[a_column].unique()\n",
    "    print(f\"{a_column} : \\n nb_nunique : {nb_nunique}  \\n perct_null : {perct_null:0.2%} \\n examples of unique values : {unique_values[0:10]} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1.4 Dataset: population_country.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>1996</td>\n",
       "      <td>83200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1996</td>\n",
       "      <td>18853437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>1996</td>\n",
       "      <td>14400719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1996</td>\n",
       "      <td>3168033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>1996</td>\n",
       "      <td>64360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name  Year     Count\n",
       "0        Aruba  1996     83200\n",
       "1  Afghanistan  1996  18853437\n",
       "2       Angola  1996  14400719\n",
       "3      Albania  1996   3168033\n",
       "4      Andorra  1996     64360"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'population_country.csv'\n",
    "df = pd.read_csv(fname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country Name : \n",
      " nb_nunique : 218  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : ['Aruba' 'Afghanistan' 'Angola' 'Albania' 'Andorra' 'United Arab Emirates'\n",
      " 'Argentina' 'Armenia' 'American Samoa' 'Antigua and Barbuda'] \n",
      "\n",
      "\n",
      "Year : \n",
      " nb_nunique : 1  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [1996] \n",
      "\n",
      "\n",
      "Count : \n",
      " nb_nunique : 218  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [   83200 18853437 14400719  3168033    64360  2539126 35246374  3168221\n",
      "    54211    70173] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df[df['Year']==1996]\n",
    "nb_rows_df = len(df)\n",
    "for a_column in df.columns :\n",
    "    nb_nunique = df[a_column].nunique()\n",
    "    perct_null = df[a_column].isnull().sum()/nb_rows_df \n",
    "    unique_values= df[a_column].unique()\n",
    "    print(f\"{a_column} : \\n nb_nunique : {nb_nunique}  \\n perct_null : {perct_null:0.2%} \\n examples of unique values : {unique_values[0:10]} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1.5 Dataset: unemployment_us_state.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>February</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Newton County</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>February</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Panola County</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>February</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Monroe County</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>February</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Hinds County</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>February</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Kemper County</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year     Month        State         County  Rate\n",
       "0  2015  February  Mississippi  Newton County   6.1\n",
       "1  2015  February  Mississippi  Panola County   9.4\n",
       "2  2015  February  Mississippi  Monroe County   7.9\n",
       "3  2015  February  Mississippi   Hinds County   6.1\n",
       "4  2015  February  Mississippi  Kemper County  10.6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'unemployment_us_state.csv'\n",
    "df = pd.read_csv(fname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year : \n",
      " nb_nunique : 1  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [1996] \n",
      "\n",
      "\n",
      "Month : \n",
      " nb_nunique : 12  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : ['February' 'October' 'March' 'August' 'May'] \n",
      "\n",
      "\n",
      "State : \n",
      " nb_nunique : 47  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : ['Mississippi' 'Oklahoma' 'Delaware' 'Minnesota' 'Illinois'] \n",
      "\n",
      "\n",
      "Rate : \n",
      " nb_nunique : 309  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [  6.3  18.2  10.4   4.2   7.3] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df[['Year','Month','State','Rate']]\n",
    "df = df[df['Year']==1996]\n",
    "nb_rows_df = len(df)\n",
    "for a_column in df.columns :\n",
    "    nb_nunique = df[a_column].nunique()\n",
    "    perct_null = df[a_column].isnull().sum()/nb_rows_df \n",
    "    unique_values= df[a_column].unique()\n",
    "    print(f\"{a_column} : \\n nb_nunique : {nb_nunique}  \\n perct_null : {perct_null:0.2%} \\n examples of unique values : {unique_values[0:5]} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1.6 Dataset: temperature.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>AvgTemperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1995</td>\n",
       "      <td>64.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1995</td>\n",
       "      <td>49.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1995</td>\n",
       "      <td>48.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1995</td>\n",
       "      <td>46.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1995</td>\n",
       "      <td>47.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Region  Country State     City  Month  Day  Year  AvgTemperature\n",
       "0  Africa  Algeria   NaN  Algiers      1    1  1995            64.2\n",
       "1  Africa  Algeria   NaN  Algiers      1    2  1995            49.4\n",
       "2  Africa  Algeria   NaN  Algiers      1    3  1995            48.8\n",
       "3  Africa  Algeria   NaN  Algiers      1    4  1995            46.4\n",
       "4  Africa  Algeria   NaN  Algiers      1    5  1995            47.9"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'temperature_country_us_state.csv'\n",
    "df = pd.read_csv(fname,low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country : \n",
      " nb_nunique : 124  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : ['Algeria' 'Burundi' 'Benin' 'Central African Republic' 'Congo' 'Egypt'\n",
      " 'Ethiopia' 'Gabon' 'Gambia' 'Guinea'] \n",
      "\n",
      "\n",
      "State : \n",
      " nb_nunique : 52  \n",
      " perct_null : 50.77% \n",
      " examples of unique values : [nan 'Alabama' 'Alaska' 'Arizona' 'Arkansas' 'California' 'Colorado'\n",
      " 'Connecticut' 'Delaware' 'District of Columbia'] \n",
      "\n",
      "\n",
      "City : \n",
      " nb_nunique : 319  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : ['Algiers' 'Bujumbura' 'Cotonou' 'Bangui' 'Brazzaville' 'Cairo'\n",
      " 'Addis Ababa' 'Libreville' 'Banjul' 'Conakry'] \n",
      "\n",
      "\n",
      "Month : \n",
      " nb_nunique : 12  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [ 1  2  3  4  5  6  7  8  9 10] \n",
      "\n",
      "\n",
      "Day : \n",
      " nb_nunique : 31  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [ 1  2  3  4  5  6  7  8  9 10] \n",
      "\n",
      "\n",
      "Year : \n",
      " nb_nunique : 1  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [1996] \n",
      "\n",
      "\n",
      "AvgTemperature : \n",
      " nb_nunique : 1311  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [ 67.4  60.   54.4  57.7  57.6  62.2  59.8  56.8  64.5  56.7] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('Region',axis=1)\n",
    "df = df[df['Year']==1996]\n",
    "nb_rows_df = len(df)\n",
    "for a_column in df.columns :\n",
    "    nb_nunique = df[a_column].nunique()\n",
    "    perct_null = df[a_column].isnull().sum()/nb_rows_df \n",
    "    unique_values= df[a_column].unique()\n",
    "    print(f\"{a_column} : \\n nb_nunique : {nb_nunique}  \\n perct_null : {perct_null:0.2%} \\n examples of unique values : {unique_values[0:10]} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country : \n",
      " nb_nunique : 1  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : ['US'] \n",
      "\n",
      "\n",
      "State : \n",
      " nb_nunique : 52  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : ['Alabama' 'Alaska' 'Arizona' 'Arkansas' 'California' 'Colorado'\n",
      " 'Connecticut' 'Delaware' 'District of Columbia' 'Maryland'] \n",
      "\n",
      "\n",
      "City : \n",
      " nb_nunique : 154  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : ['Birmingham' 'Huntsville' 'Mobile' 'Montgomery' 'Anchorage' 'Fairbanks'\n",
      " 'Juneau' 'Flagstaff' 'Phoenix' 'Tucson'] \n",
      "\n",
      "\n",
      "Month : \n",
      " nb_nunique : 12  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [ 1  2  3  4  5  6  7  8  9 10] \n",
      "\n",
      "\n",
      "Day : \n",
      " nb_nunique : 31  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [ 1  2  3  4  5  6  7  8  9 10] \n",
      "\n",
      "\n",
      "Year : \n",
      " nb_nunique : 1  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [1996] \n",
      "\n",
      "\n",
      "AvgTemperature : \n",
      " nb_nunique : 1208  \n",
      " perct_null : 0.00% \n",
      " examples of unique values : [ 56.8  59.8  37.4  35.5  43.8  50.2  26.   22.7  31.8  39.1] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df[df['Country']=='US']\n",
    "nb_rows_df = len(df)\n",
    "for a_column in df.columns :\n",
    "    nb_nunique = df[a_column].nunique()\n",
    "    perct_null = df[a_column].isnull().sum()/nb_rows_df \n",
    "    unique_values= df[a_column].unique()\n",
    "    print(f\"{a_column} : \\n nb_nunique : {nb_nunique}  \\n perct_null : {perct_null:0.2%} \\n examples of unique values : {unique_values[0:10]} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.2 Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.1 Dataset: i94_apr16_sub.sas7bdat\n",
    "    We will use the dataset \"i94_apr16_sub.sas7bdat\" to create the table \"I94s\".\n",
    "    We have just seen on 2.1.1 that only the columns visapost, occup, entdepu, insnum have more than 40% of NULL values.\n",
    "    We also saw that the column \"count\" has one unique value \"1\" so this column is irrevelant.\n",
    "    \n",
    "    Therefore we will not use those columns to create the fact table \"I94s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.2 Dataset: political_stability_country.csv\n",
    "    We will use the dataset \"political_stability_country.csv\" to create the column \"pss = Political stability score\" of the dimension table \"economics_country\".\n",
    "    \n",
    "    We have just seen on 2.1.2 that the columns 'Series Name' and 'Series Code' are not relevant. The others columns are coherent with small percentage of NULL values; so we will keep them to create the column \"pss = Political stability score\" of the dimension table \"economics_country\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.3 Dataset: unemployment_country.csv\n",
    "    We will use the dataset \"unemployment_country.csv\" to create the columns \"uwae = Unemployment with advanced education\",\"uwbe = Unemployment with basic education\",\"uwie = Unemployment with intermediate education\",\"ut = Unemployment total\" of the dimension table \"economics_country\".\n",
    "    \n",
    "    We have just seen on 2.1.3 that all columns of the datasets are coherent with small percentage of NULL values. So we will keep them to create the columns of the dimension table \"economics_country\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.4 Dataset: population_country.csv\n",
    "    We will use the dataset \"population_country.csv\" to create the column \"powp (=percentage of world population)\" of the dimension table \"economics_country\".\n",
    "    \n",
    "    We have just seen on 2.1.4 that all the columns are coherent with small percentage of NULL values. So we will keep them to create the column \"powp\" of the dimension table \"economics_country\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.5 Dataset: unemployment_us_state.csv\n",
    "    We will use the dataset \"unemployment_us_state.csv\" to create the column \"ut = Unemployment total\" of the dimension table \"economics_us_state\".\n",
    "    \n",
    "    We have just seen on 2.1.5 see that only the columns 'Year','Month','State','Rate' are relevant. And these columns are coherent with small percentage of NULL values. So we will keep them to create the column \"ut = Unemployment total\" of the dimension table \"economics_us_state\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.6 Dataset: temperature_country_us_state.csv\n",
    "    We will use the dataset \"temperature_country_us_state.csv\" to create the table \"temperature_us_state\" and \"temperature_country\".\n",
    "    \n",
    "    We have just seen on 2.1.6 that the column 'Region' is not relevant. All the other columns are coherent with small percentage of NULL values; so we will keep them to create the dimension tables \"temperature_us_state\" and \"temperature_country\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3: The Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "    We chose a star schema as data model because the files from I94 Immigration Data are a natural fact table. \n",
    "\n",
    "    The fact table provides information on individuals arring to the U.S. More specificaly we can see with column i94res the country of residency before arring in the U.S. And we can see with the column i94addr the state of residency in the U.S. So we thought it will be interesting to link weather and economical informartion on the country of residency before arring in the U.S and the state of residency in the U.S.\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List of the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "##### 3.2.1 Create the dimension table \"economics_country\" :\n",
    "\n",
    "    create 3 Spark dataframes :\n",
    "        \"political_stability_country\" from political_stability_country.csv and remove irrelevant columns\n",
    "        \"unemployment_country\" from unemployment_country.csv and remove irrelevant columns\n",
    "        \"population_country\" from population_country.csv and remove irrelevant columns\n",
    "\n",
    "    from those 3 Spark dataframes create a Spark dataframe \"economics_country\"\n",
    "\n",
    "    from the Spark dataframe \"economics_country\" create the final dimension table \"economics_country\" \n",
    "    \n",
    "    add a primary key column.\n",
    "\n",
    "\n",
    "##### 3.2.1 Create the dimension table \"economics_us_state\" :\n",
    "\n",
    "    create the Spark dataframes \"unemployment_us_state\" from unemployment_us_state.csv and remove irrelevant columns\n",
    "\n",
    "    from the Spark dataframe \"unemployment_us_state\" create the final dimension table \"economics_us_state\" \n",
    "    \n",
    "    add a primary key column.\n",
    "\n",
    "\n",
    "##### 3.2.2 Create the dimension table \"temperature_country\" :\n",
    "\n",
    "    create the Spark dataframes \"temperature_country\" from temperature_country_us_state.csv and remove irrelevant columns\n",
    "\n",
    "    from the Spark dataframe \"temperature_country\" create the final dimension table \"temperature_country\" \n",
    "\n",
    "    add a primary key column.\n",
    "\n",
    "\n",
    "##### 3.2.3 Create the dimension table \"temperature_us_state\" :\n",
    "\n",
    "    create the Spark dataframes \"temperature_us_state\" from temperature_country_us_state.csv and remove irrelevant columns\n",
    "\n",
    "    from the Spark dataframe \"temperature_us_state\" create the final dimension table \"temperature_us_state\" \n",
    "\n",
    "\n",
    "    add a primary key column.\n",
    "\n",
    "##### 3.2.4 Create the fact table \"I94s\" :\n",
    "\n",
    "    create the Spark dataframes \"I94s\" from political_stability_country.csv and remove irrelevant columns\n",
    "\n",
    "    add  four columns to the Spark dataframes \"I94s\": \n",
    "                economics_country_id that points to column id of Spark dataframe \"economics_country\" \n",
    "                temperature_country_id that points to column id of Spark dataframe \"temperature_country\" \n",
    "                economics_us_state_id that points to column id of Spark dataframe \"economics_us_state\" \n",
    "                temperature_us_state_id that points to column id of Spark dataframe \"temperature_us_state\" \n",
    "\n",
    "    from the Spark dataframe \"I94s\" create the final fact table \"I94s\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4: Run The Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Please run the file etl.py below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here\n",
    "! python etl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# we load the fact/dimension tables into TempViews:\n",
    "\n",
    "economics_country = spark.read.parquet(\"fact_dimension_tables_01/economics_country.parquet\")\n",
    "economics_country.createOrReplaceTempView(\"economics_country_view\")\n",
    "\n",
    "economics_us_state = spark.read.parquet(\"fact_dimension_tables_01/economics_us_state.parquet\")\n",
    "economics_us_state.createOrReplaceTempView(\"economics_us_state_view\")\n",
    "\n",
    "temperature_country = spark.read.parquet(\"fact_dimension_tables_01/temperature_country.parquet\")\n",
    "temperature_country.createOrReplaceTempView(\"temperature_country_view\")\n",
    "\n",
    "temperature_us_state = spark.read.parquet(\"fact_dimension_tables_01/temperature_us_state.parquet\")\n",
    "temperature_us_state.createOrReplaceTempView(\"temperature_us_state_view\")\n",
    "\n",
    "I94s = spark.read.parquet(\"fact_dimension_tables_01/I94s.parquet\")\n",
    "I94s.createOrReplaceTempView(\"I94s_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "economics_country\n",
      "+-------------------------+-------------------------------------------------------------------------+\n",
      "|max(id_economics_country)|(CAST(max(id_economics_country) AS BIGINT) = count(id_economics_country))|\n",
      "+-------------------------+-------------------------------------------------------------------------+\n",
      "|                     4551|                                                                     true|\n",
      "+-------------------------+-------------------------------------------------------------------------+\n",
      "\n",
      "economics_us_state\n",
      "+--------------------------+---------------------------------------------------------------------------+\n",
      "|max(id_economics_us_state)|(CAST(max(id_economics_us_state) AS BIGINT) = count(id_economics_us_state))|\n",
      "+--------------------------+---------------------------------------------------------------------------+\n",
      "|                      4965|                                                                       true|\n",
      "+--------------------------+---------------------------------------------------------------------------+\n",
      "\n",
      "temperature_country\n",
      "+---------------------------+-----------------------------------------------------------------------------+\n",
      "|max(id_temperature_country)|(CAST(max(id_temperature_country) AS BIGINT) = count(id_temperature_country))|\n",
      "+---------------------------+-----------------------------------------------------------------------------+\n",
      "|                      34036|                                                                         true|\n",
      "+---------------------------+-----------------------------------------------------------------------------+\n",
      "\n",
      "temperature_us_state\n",
      "+----------------------------+-------------------------------------------------------------------------------+\n",
      "|max(id_temperature_us_state)|(CAST(max(id_temperature_us_state) AS BIGINT) = count(id_temperature_us_state))|\n",
      "+----------------------------+-------------------------------------------------------------------------------+\n",
      "|                       13304|                                                                           true|\n",
      "+----------------------------+-------------------------------------------------------------------------------+\n",
      "\n",
      "I94s\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 3096313|\n",
      "+--------+\n",
      "\n",
      "Count of rows of the Inner join of the fact table with all the dimension tables:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1446152"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the four dimension tables the the id columns have unique non null values:\n",
    "\n",
    "# economics_country\n",
    "print(\"economics_country\")\n",
    "spark.sql(\"SELECT max(id_economics_country), max(id_economics_country) == count(id_economics_country) FROM economics_country_view \").show()\n",
    "\n",
    "\n",
    "# economics_us_state\n",
    "print(\"economics_us_state\")\n",
    "spark.sql(\"SELECT max(id_economics_us_state),max(id_economics_us_state) == count(id_economics_us_state) FROM economics_us_state_view \").show()\n",
    "\n",
    "\n",
    "# temperature_country\n",
    "print(\"temperature_country\")\n",
    "spark.sql(\"SELECT max(id_temperature_country),max(id_temperature_country) == count(id_temperature_country) FROM temperature_country_view \").show()\n",
    "\n",
    "\n",
    "# temperature_us_state\n",
    "print(\"temperature_us_state\")\n",
    "spark.sql(\"SELECT max(id_temperature_us_state),max(id_temperature_us_state) == count(id_temperature_us_state) FROM temperature_us_state_view \").show()\n",
    "\n",
    "\n",
    "# Check if the fact table has a coherent numbers of rows:\n",
    "\n",
    "# I94s\n",
    "print(\"I94s\")\n",
    "spark.sql(\"SELECT count(*) FROM I94s_view\").show()\n",
    "\n",
    "\n",
    "# Check if the data model works: \n",
    "# We are goinf to inner join the fact table with all the dimension tables and count the number of rows.\n",
    "# If the count of rows is in the same order of magnitude as to number of rows of I94s, then the data model works\n",
    "\n",
    "print(\"Count of rows of the Inner join of the fact table with all the dimension tables:\")\n",
    "query = spark.sql(\" \\\n",
    "SELECT i94yr,i94mon,i94res,i94addr, \\\n",
    "economics_country_view.country_name as ec_country_name, \\\n",
    "economics_country_view.country_code as ec_country_code, \\\n",
    "economics_country_view.year as ec_year, \\\n",
    "pss as ec_pss, \\\n",
    "uwae as ec_uwae, \\\n",
    "uwbe as ec_uwbe, \\\n",
    "uwie as ec_uwie, \\\n",
    "economics_country_view.ut as ec_ut, \\\n",
    "powp as ec_powp, \\\n",
    "economics_us_state_view.state_name as eus_state_name, \\\n",
    "economics_us_state_view.state_code as eus_state_code, \\\n",
    "economics_us_state_view.year as eus_year, \\\n",
    "economics_us_state_view.month as eus_month, \\\n",
    "economics_us_state_view.ut as eus_ut, \\\n",
    "temperature_country_view.country_name as tcv_country_name, \\\n",
    "temperature_country_view.country_code as tcv_country_code, \\\n",
    "temperature_country_view.year as tcv_year, \\\n",
    "temperature_country_view.month as tcv_month, \\\n",
    "temperature_country_view.temperature as tcv_temperature, \\\n",
    "temperature_country_view.min_temperature as tcv_min_temperature, \\\n",
    "temperature_country_view.max_temperature as tcv_max_temperature, \\\n",
    "temperature_us_state_view.state_name as tus_state_name, \\\n",
    "temperature_us_state_view.state_code as tus_state_code, \\\n",
    "temperature_us_state_view.year as tus_year, \\\n",
    "temperature_us_state_view.month as tus_month, \\\n",
    "temperature_us_state_view.temperature as tus_temperature, \\\n",
    "temperature_us_state_view.min_temperature as tus_min_temperature, \\\n",
    "temperature_us_state_view.max_temperature as tus_max_temperature \\\n",
    "FROM I94s_view \\\n",
    "INNER JOIN economics_country_view ON I94s_view.id_economics_country=economics_country_view.id_economics_country \\\n",
    "INNER JOIN economics_us_state_view ON I94s_view.id_economics_us_state=economics_us_state_view.id_economics_us_state \\\n",
    "INNER JOIN temperature_country_view ON I94s_view.id_temperature_country=temperature_country_view.id_temperature_country \\\n",
    "INNER JOIN temperature_us_state_view ON I94s_view.id_temperature_us_state=temperature_us_state_view.id_temperature_us_state \\\n",
    "\")\n",
    "query.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"schema.png\",width=600,height=600>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"schema.png\",width=600,height=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "- The dimension tables: \n",
    "\n",
    "\"economics_country\": \n",
    "            \n",
    "            id_economics_country (primary key), year, country_name, pss, uwae, uwbe, uwie, ut, country_code\n",
    "\n",
    "            pss = Political stability score \n",
    "            uwae = Unemployment percentage with advanced education\n",
    "            uwbe = Unemployment percentage with basic education\n",
    "            uwie = Unemployment percentage with intermediate education\n",
    "            ut = Unemployment percentage total\n",
    "            powp = percentage of world population\n",
    "            \n",
    "            ps: for each country_name the country_code was provided on I94_SAS_Labels_Descriptions.SAS file\n",
    "\n",
    "\"temperature_country\":\n",
    "            \n",
    "            id_temperature_country (primary key), year, month, country_code, country_name, temperature, min_temperature, max_temperature\n",
    "            \n",
    "            ps: for each country_name the country_code was provided on I94_SAS_Labels_Descriptions.SAS file\n",
    "\n",
    "\"economics_us_state\":\n",
    "\n",
    "            id_economics_us_state (primary key), year, state_code, state_name, ut\n",
    "            \n",
    "            ut = Unemployment percentage total\n",
    "            \n",
    "            ps: for each state_name the state_code was provided on I94_SAS_Labels_Descriptions.SAS file\n",
    "\n",
    "\n",
    "\"temperature_us_state\":\n",
    "\n",
    "            id_temperature_us_state (primary key), year, month, state_code, state_name, temperature, min_temperature, max_temperature\n",
    "            \n",
    "            ps: for each state_name the state_code was provided on I94_SAS_Labels_Descriptions.SAS file\n",
    "\n",
    "- The fact table:\n",
    "\n",
    "\"I94s\": \n",
    "\n",
    "            Each row will repersent DHS Arrival/Departure Record issued to aliens who are admitted to the U.S., \n",
    "            who are adjusting status while in the U.S. or extending their stay, among other things. \n",
    "            ps: An alien is any individual who is not a U.S. citizen or U.S. national.\n",
    "            \n",
    "            cicid : unique nunber given to each form I-94. Reset each month, so concact(cicid,I94YR,I94MON) is an unique number\n",
    "            i94yr : year\n",
    "            i94mon : month\n",
    "            i94cit: country code for the alien residency\n",
    "            \n",
    "            i94res : country code for residency before arring in the U.S.\n",
    "            i94port :  airport/port of arrival to the U.S.\n",
    "            arrdate : arrival date in the U.S. (timestamp)\n",
    "            i94mode : travel mode ()\n",
    "            i94addr : US state code for current address in U.S.\n",
    "            \n",
    "            depdate : departure date from the U.S. (timestamp)\n",
    "            i94bir : age\n",
    "            i94visa : general visa\n",
    "            dtadfile : date at the time the form I-94 was filled\n",
    "            visapost : department of state where visa was issued (codes no provided)\n",
    "            occup : occupation in U.S. (codes no provided)\n",
    "            entdepa : arrival flag admitted or paroled into the U.S. (codes no provided)\n",
    "            entdepd : departure flag departed, lost I-94 or is deceased (codes no provided)\n",
    "            entdepu : update flag either apprehended, overstayed, adjusted to perm residence (codes no provided)\n",
    "            matflag : match flagMatch of arrival and departure records (codes no provided)\n",
    "            biryear : birth_year\n",
    "            dtaddto : allowed to stay until date (timestamp)\n",
    "            gender : gender\n",
    "            insnum : INS number\n",
    "            airline : airline used to arrive in U.S. (codes no provided)\n",
    "            admnum : admission number,\n",
    "            fltno : flight number of airline used to arrive in U.S.\n",
    "            visatype : visa type (codes no provided)\n",
    "            \n",
    "            We added four columns: \n",
    "\n",
    "            economics_country_id that points to column id of \"economics_country\" table\n",
    "            temperature_country_id that points to column id of \"temperature_country\" table\n",
    "            economics_us_state_id that points to column id of \"economics_us_state\" table\n",
    "            temperature_us_state_id that points to column id of \"temperature_us_state\" table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5:Project Write Up\n",
    "\n",
    "\n",
    "##### ETL has processed the result in the final data model beacuse we see on the Data Quality Checks section above that count of rows of the inner join of the fact table and all the dimesion tables is in the same order of magnitude as to number of rows of the fact table.\n",
    "\n",
    "\n",
    "##### For this projecy we have choosen PySpark, because PySpark is very efficient for processing large datasets.\n",
    "\n",
    "##### The point of the database that we are creating is to link weather and economical informartion on the country of residency before arring in the U.S and the state of residency in the U.S.\n",
    "##### Weather and economical informartion information is not meaningfull if we look at it day by day. It starts to be meaningfull if we look at it month by month. Also we see on https://www.trade.gov/i-94-arrivals-program that the immigration dataset is release every month. So the data should be updated ever month.\n",
    "\n",
    " ##### If the data was increased by 100x then the pipeline should be run on AWS EMR clusters. That way we could use the full potential of Pyspark Pipeline. Apache Spark is linearly scalable, which means we may simply add the number of clusters to increase the performance. With AWS EMR we will be able to adjust the size and number of clusters as we see fit\n",
    " \n",
    " ##### If the data populates a dashboard that must be updated on a daily basis by 7am every day  then we should use Airflow so the pipeline is excetuded automatically every day before 7am.\n",
    " \n",
    " #####  If the database needed to be accessed by 100+ people then the tables should be located on AWS Redshift.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
